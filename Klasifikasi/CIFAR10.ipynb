{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmf_JRJa_N8C"
   },
   "source": [
    "TUGAS BESAR\n",
    "1. Klasfisikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKA_J7bdP33T"
   },
   "outputs": [],
   "source": [
    "# reference:\n",
    "#\n",
    "# Â© MIT 6.S191: Introduction to Deep Learning\n",
    "# http://introtodeeplearning.com\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm1XpLftPi4A"
   },
   "source": [
    "\n",
    "# Part 1: CIFAR10 Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RsGqx_ai_N8F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "# Import Tensorflow 2.0\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf \n",
    "\n",
    "!pip install mitdeeplearning\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "assert len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKjrdUtX_N8J"
   },
   "source": [
    "## 1.1 CIFAR10 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2dQsHI3_N8K"
   },
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images = (np.expand_dims(train_images, axis=-1)/255.).astype(np.float32)\n",
    "train_labels = (train_labels).astype(np.int64)\n",
    "test_images = (np.expand_dims(test_images, axis=-1)/255.).astype(np.float32)\n",
    "test_labels = (test_labels).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZtUqOqePsRD"
   },
   "source": [
    "This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDBsR2lP_N8O",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "random_inds = np.random.choice(50000,36)\n",
    "for i in range(36):\n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    image_ind = random_inds[i]\n",
    "    plt.imshow(np.squeeze(train_images[image_ind]), cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[image_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6hd3Nt1_N8q"
   },
   "source": [
    "## 1.2 Neural Network for Picture Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rphS2rMIymyZ"
   },
   "source": [
    "### Fully connected neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMZsbjAkDKpU"
   },
   "outputs": [],
   "source": [
    "def build_fc_model():\n",
    "  fc_model = tf.keras.Sequential([\n",
    "      # First define a Flatten layer\n",
    "      tf.keras.layers.Flatten(),\n",
    "\n",
    "      # '''TODO: Define the activation function for the first fully connected (Dense) layer.'''\n",
    "      tf.keras.layers.Dense(128, activation= '''TODO'''),\n",
    "\n",
    "      # '''TODO: Define the second Dense layer to output the classification probabilities'''\n",
    "      '''TODO: Dense layer to output classification probabilities'''\n",
    "      \n",
    "  ])\n",
    "  return fc_model\n",
    "\n",
    "model = build_fc_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "\n",
    "\n",
    "### Compile the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "'''TODO: Experiment with different optimizers and learning rates. How do these affect\n",
    "    the accuracy of the trained model? Which optimizers and/or learning rates yield\n",
    "    the best performance?'''\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFMbIqIvQ2X0"
   },
   "outputs": [],
   "source": [
    "# Define the batch size and the number of epochs to use during training\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEw4bZgGCaXB"
   },
   "source": [
    "### Evaluate accuracy on the test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": [
    "'''TODO: Use the evaluate method to test the model!'''\n",
    "test_loss, test_acc = # TODO\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baIw9bDf8v6Z"
   },
   "source": [
    "## 1.3 Convolutional Neural Network (CNN) for handwritten digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J72Yt1o_fY7"
   },
   "source": [
    "\n",
    "\n",
    "![alt_text](https://raw.githubusercontent.com/aamini/introtodeeplearning/master/lab2/img/convnet_fig.png \"CNN Architecture for MNIST Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEHqzbJJAEoR"
   },
   "source": [
    "### Define the CNN model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vec9qcJs-9W5"
   },
   "outputs": [],
   "source": [
    "def build_cnn_model():\n",
    "    cnn_model = tf.keras.Sequential([\n",
    "\n",
    "        # TODO: Define the first convolutional layer\n",
    "        tf.keras.layers.Conv2D('''TODO'''), \n",
    "\n",
    "        # TODO: Define the first max pooling layer\n",
    "        tf.keras.layers.MaxPool2D('''TODO'''),\n",
    "\n",
    "        # TODO: Define the second convolutional layer\n",
    "        tf.keras.layers.Conv2D('''TODO'''),\n",
    "\n",
    "        # TODO: Define the second max pooling layer\n",
    "        tf.keras.layers.MaxPool2D('''TODO'''),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "\n",
    "        # TODO: Define the last Dense layer to output the classification \n",
    "        # probabilities. Pay attention to the activation needed a probability\n",
    "        # output\n",
    "        '''TODO: Dense layer to output classification probabilities'''\n",
    "    ])\n",
    "    \n",
    "    return cnn_model\n",
    "  \n",
    "cnn_model = build_cnn_model()\n",
    "# Initialize the model by passing some data through\n",
    "cnn_model.predict(train_images[[0]])\n",
    "# Print the summary of the layers in the model.\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUAXIBynCih2"
   },
   "source": [
    "### Train and test the CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vheyanDkCg6a"
   },
   "outputs": [],
   "source": [
    "'''TODO: Define the compile operation with your optimizer and learning rate of choice'''\n",
    "cnn_model.compile(optimizer='''TODO''', loss='''TODO''', metrics=['accuracy']) # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U19bpRddC7H_"
   },
   "source": [
    "As was the case with the fully connected model, we can train our CNN using the `fit` method via the Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdrGZVmWDK4p"
   },
   "outputs": [],
   "source": [
    "'''TODO: Use model.fit to train the CNN model, with the same batch_size and number of epochs previously used.'''\n",
    "cnn_model.fit('''TODO''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEszYWzgDeIc"
   },
   "source": [
    "Great! Now that we've trained the model, let's evaluate it on the test dataset using the [`evaluate`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#evaluate) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDm4znZcDtNl"
   },
   "outputs": [],
   "source": [
    "'''TODO: Use the evaluate method to test the model!'''\n",
    "test_loss, test_acc = # TODO\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsoS7CPDCaXH"
   },
   "source": [
    "### Make predictions with the CNN model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": [
    "predictions = cnn_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9Kk1voUCaXJ"
   },
   "source": [
    "With this function call, the model has predicted the label for each image in the testing set. Let's take a look at the prediction for the first image in the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DmJEUinCaXK"
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hw1hgeSCaXN"
   },
   "source": [
    "As you can see, a prediction is an array of 10 numbers. Recall that the output of our model is a probability distribution over the 10 digit classes. Thus, these numbers describe the model's \"confidence\" that the image corresponds to each of the 10 different digits. \n",
    "\n",
    "Let's look at the digit that has the highest confidence for the first image in the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsqenuPnCaXO"
   },
   "outputs": [],
   "source": [
    "'''TODO: identify the digit with the highest confidence prediction for the first\n",
    "    image in the test dataset. '''\n",
    "prediction = # TODO\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E51yS7iCCaXO"
   },
   "source": [
    "So, the model is most confident that this image is a \"???\". We can check the test label (remember, this is the true identity of the digit) to see if this prediction is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sd7Pgsu6CaXP"
   },
   "outputs": [],
   "source": [
    "print(\"Label of this digit is:\", test_labels[0])\n",
    "plt.imshow(test_images[0,:,:,0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygh2yYC972ne"
   },
   "source": [
    "It is! Let's visualize the classification results on the MNIST dataset. We will plot images from the test dataset along with their predicted label, as well as a histogram that provides the prediction probabilities for each of the digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "#@title Change the slider to look at the model's predictions! { run: \"auto\" }\n",
    "\n",
    "image_index = 79 #@param {type:\"slider\", min:0, max:100, step:1}\n",
    "plt.subplot(1,2,1)\n",
    "mdl.lab2.plot_image_prediction(image_index, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "mdl.lab2.plot_value_prediction(image_index, predictions,  test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "We can also plot several images along with their predictions, where correct prediction labels are blue and incorrect prediction labels are grey. The number gives the percent confidence (out of 100) for the predicted label. Note the model can be very confident in an incorrect prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "# Plots the first X test images, their predicted label, and the true label\n",
    "# Color correct predictions in blue, incorrect predictions in red\n",
    "num_rows = 5\n",
    "num_cols = 4\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  mdl.lab2.plot_image_prediction(i, predictions, test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  mdl.lab2.plot_value_prediction(i, predictions, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-2glsRiMdqa"
   },
   "source": [
    "## 1.4 Training the model 2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wq34id-iN1Ml"
   },
   "outputs": [],
   "source": [
    "# Rebuild the CNN model\n",
    "cnn_model = build_cnn_model()\n",
    "\n",
    "batch_size = 12\n",
    "loss_history = mdl.util.LossHistory(smoothing_factor=0.95) # to record the evolution of the loss\n",
    "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss', scale='semilogy')\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2) # define our optimizer\n",
    "\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
    "\n",
    "for idx in tqdm(range(0, train_images.shape[0], batch_size)):\n",
    "  # First grab a batch of training data and convert the input images to tensors\n",
    "  (images, labels) = (train_images[idx:idx+batch_size], train_labels[idx:idx+batch_size])\n",
    "  images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "\n",
    "  # GradientTape to record differentiation operations\n",
    "  with tf.GradientTape() as tape:\n",
    "    #'''TODO: feed the images into the model and obtain the predictions'''\n",
    "    logits = # TODO\n",
    "\n",
    "    #'''TODO: compute the categorical cross entropy loss\n",
    "    loss_value = tf.keras.backend.sparse_categorical_crossentropy() # TODO\n",
    "\n",
    "  loss_history.append(loss_value.numpy().mean()) # append the loss to the loss_history record\n",
    "  plotter.plot(loss_history.get())\n",
    "\n",
    "  # Backpropagation\n",
    "  '''TODO: Use the tape to compute the gradient against all parameters in the CNN model.\n",
    "      Use cnn_model.trainable_variables to access these parameters.''' \n",
    "  grads = # TODO\n",
    "  optimizer.apply_gradients(zip(grads, cnn_model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cNtDhVaqEdR"
   },
   "source": [
    "## 1.5 Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Xmf_JRJa_N8C"
   ],
   "name": "Part1_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
